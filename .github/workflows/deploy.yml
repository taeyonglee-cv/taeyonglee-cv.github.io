name: Deploy to GitHub Pages

on:
  push:
    branches:
      - main
  schedule:
    - cron: '0 0 * * *'  # 3일마다 새벽 2시

permissions:
  contents: read
  pages: write
  id-token: write
  
jobs:
  update-citations:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - uses: actions/setup-node@v4
        with:
          node-version: '20'
          
      - name: Install dependencies
        run: npm install
        
      - name: Run scholar crawler with proxy support
        run: |
          echo "Starting Google Scholar citation update with proxy support..."
          
          # 기존 데이터 백업
          if [ -f data/publications.json ]; then
            echo "📋 Found existing publications.json, creating backup"
            cp data/publications.json data/publications.json.backup
          else
            echo "📁 No existing publications.json found"
            mkdir -p data
            echo "[]" > data/publications.json
          fi
          
          # 프록시 크롤러가 있으면 우선 사용
          SUCCESS=false
          
          if [ -f scripts/proxy-scholar-crawler.js ]; then
            echo "🌐 Method 1: Using proxy crawler..."
            if node scripts/proxy-scholar-crawler.js; then
              echo "✅ Proxy crawler succeeded"
              SUCCESS=true
            else
              echo "❌ Proxy crawler failed"
            fi
          fi
          
          # 프록시 방법이 실패하면 기존 방법으로 재시도
          if [ "$SUCCESS" = false ]; then
            echo "🔄 Method 2: Fallback to direct crawler with retry..."
            
            for i in {1..3}; do
              echo "🔄 Direct attempt $i/3..."
              
              if node scripts/scholar-citation-crawler.js; then
                echo "✅ Direct crawler succeeded on attempt $i"
                SUCCESS=true
                break
              else
                echo "❌ Direct attempt $i failed"
                if [ $i -lt 3 ]; then
                  WAIT_TIME=$((45 + i * 30))  # 45초, 75초
                  echo "⏳ Waiting ${WAIT_TIME} seconds..."
                  sleep $WAIT_TIME
                fi
              fi
            done
          fi
          
          # 모든 방법이 실패한 경우 기존 데이터 유지
          if [ "$SUCCESS" = false ]; then
            echo ""
            echo "⚠️ All methods failed, but continuing with existing data"
            
            if [ -f data/publications.json.backup ]; then
              echo "📋 Restoring from backup"
              cp data/publications.json.backup data/publications.json
            fi
            
            if [ ! -f data/publications.json ] || [ ! -s data/publications.json ]; then
              echo "📝 Creating empty publications file"
              echo "[]" > data/publications.json
            fi
          fi
          
          # 백업 파일 정리
          rm -f data/publications.json.backup
          
          # 최종 상태 확인
          echo ""
          echo "📊 Final publications.json status:"
          if [ -f data/publications.json ]; then
            FILE_SIZE=$(wc -c < data/publications.json)
            echo "✅ File exists ($FILE_SIZE bytes)"
            if [ $FILE_SIZE -gt 2 ]; then
              echo "📖 Content preview:"
              head -n 5 data/publications.json
            fi
          else
            echo "❌ File does not exist"
            exit 1
          fi
        continue-on-error: false
        
      - name: Verify publications data
        run: |
          echo "🔍 Verifying publications.json..."
          
          if [ ! -f data/publications.json ]; then
            echo "❌ publications.json not found!"
            exit 1
          fi
          
          # JSON 유효성 검사
          if ! python3 -m json.tool data/publications.json > /dev/null 2>&1; then
            echo "❌ Invalid JSON format!"
            echo "📄 File content:"
            cat data/publications.json
            exit 1
          fi
          
          # 파일 크기 확인
          FILE_SIZE=$(wc -c < data/publications.json)
          echo "📏 File size: $FILE_SIZE bytes"
          
          if [ $FILE_SIZE -lt 2 ]; then
            echo "❌ File too small (likely empty or corrupted)"
            exit 1
          fi
          
          echo "✅ publications.json is valid"
          
      - name: Save updated publications.json
        uses: actions/upload-artifact@v4
        with:
          name: updated-data
          path: data/publications.json

  deploy:
    needs: update-citations
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    steps:
      - uses: actions/checkout@v4
      
      - name: Download updated publications.json
        uses: actions/download-artifact@v4
        with:
          name: updated-data
          path: tmp
          
      - name: Overwrite publications.json in repo
        run: |
          echo "📁 Setting up data directory..."
          mkdir -p data
          
          echo "📋 Copying updated publications.json..."
          cp tmp/publications.json data/publications.json
          
          echo "🔍 Verifying copied file..."
          if [ -f data/publications.json ]; then
            FILE_SIZE=$(wc -c < data/publications.json)
            echo "✅ File copied successfully ($FILE_SIZE bytes)"
            
            # 내용 미리보기
            echo "📖 Publications preview:"
            head -n 10 data/publications.json | sed 's/^/   /'
          else
            echo "❌ Failed to copy publications.json"
            exit 1
          fi
          
      - name: Setup Pages
        uses: actions/configure-pages@v5
        
      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: .
          
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
        
      - name: Deployment summary
        run: |
          echo "🚀 Deployment completed!"
          echo "🔗 Site URL: ${{ steps.deployment.outputs.page_url }}"
          echo "📅 Deployed at: $(date)"
